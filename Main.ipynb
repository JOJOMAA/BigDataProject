{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5cf04f25b6738a3",
   "metadata": {},
   "source": [
    "## Demografische Entwicklung Wiens seit 2008: Analyse der\n",
    "## Bevölkerungsstruktur und Geburtenentwicklung auf\n",
    "## Bezirksebene\n",
    "<u>**Big Data Projekt von:**</u>\n",
    "<br>\n",
    "Johannes Reitterer <br>\n",
    "Johannes Mantler <br>\n",
    "Nicolas Nemeth <br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92be410d77233692",
   "metadata": {},
   "source": [
    "# ETL Pipeline\n",
    "Diese ETL-Pipeline lädt demografische Daten der Stadt Wien, bereinigt sie und speichert sie in MongoDB zur weiteren Analyse.\n",
    "\n",
    "**Datenquellen:**\n",
    "- Bevölkerung nach Geburtsbundesland (2008-heute): ~500.000 Datensätze https://www.data.gv.at/datasets/f54e6828-3d75-4a82-89cb-23c58057bad4?locale=de\n",
    "- Geburtenstatistik (2002-heute): ~50.000 Datensätze https://www.data.gv.at/datasets/f54e6828-3d75-4a82-89cb-23c58057bad4?locale=de\n",
    "\n",
    "## Pipeline-Ablauf\n",
    "\n",
    "### 1. Extract (Daten laden)\n",
    "\n",
    "Die Rohdaten werden aus CSV-Dateien von data.gv.at geladen.\n",
    "\n",
    "Da es Probleme bei der API-Abfrage gibt, müssen die csv files manuell gedownloaded werden und in den Projekt Ordner eingefügt werden.\n",
    "\n",
    "### 2. Transform (Daten bereinigen)\n",
    "\n",
    "**Spaltenumbenennung:**\n",
    "- Englische Spaltennamen werden zu deutschen Namen konvertiert\n",
    "- Beispiel: `REF_YEAR` → `Jahr`, `DISTRICT_CODE` → `Bezirk_Roh`\n",
    "\n",
    "**Bezirkscode-Transformation:**\n",
    "\n",
    "Wien verwendet statistische Codes (90101-90223), die zu Postleitzahlen konvertiert werden:\n",
    "\n",
    "```\n",
    "90101 → 1010 (1. Bezirk)\n",
    "90201 → 1020 (2. Bezirk)\n",
    "90301 → 1030 (3. Bezirk)\n",
    "...\n",
    "```\n",
    "\n",
    "**Datenbereinigung:**\n",
    "- Ungültige Bezirkscodes entfernen\n",
    "- Fehlende Werte mit 0 auffüllen\n",
    "- Negative Werte korrigieren\n",
    "- Datentypen zu Integer konvertieren\n",
    "\n",
    "(1 = Männer, 2 = Frauen)\n",
    "\n",
    "### 3. Load (Daten speichern)\n",
    "\n",
    "Die bereinigten Daten werden in MongoDB gespeichert:\n",
    "- **Collection `population`**: Bevölkerungsdaten nach Bezirk, Jahr, Alter, Geschlecht und Herkunft\n",
    "- **Collection `births`**: Geburtendaten nach Bezirk, Jahr und Geschlecht\n",
    " \n",
    "**Dokumentstruktur Beispiel:**\n",
    "```json\n",
    "{\n",
    "  \"Jahr\": 2020,\n",
    "  \"Bezirk\": 1010,\n",
    "  \"Geschlecht\": 1,\n",
    "  \"Alter\": 25,\n",
    "  \"Wien\": 1234,\n",
    "  \"Ausland\": 789\n",
    "}\n",
    "```\n",
    "\n",
    "## Verwendung\n",
    "\n",
    "```python\n",
    "# Pipeline ausführen\n",
    "run_pipeline()\n",
    "\n",
    "# Ergebnis: Daten in MongoDB unter wien_demografie_db\n",
    "# - population: Bevölkerungsdaten\n",
    "# - births: Geburtendaten\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "id": "525e698f13ddee9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T13:21:52.633639Z",
     "start_time": "2026-01-09T13:21:51.908857Z"
    }
   },
   "source": [
    "\"\"\"\"\n",
    "Authors: Johannes Mantler, Johannes Reitterer, Nicolas Nemeth\n",
    "\n",
    "Data Sources:\n",
    "- Population by province of birth (2008-present) https://www.data.gv.at/datasets/98b782ca-8e46-43d7-a061-e196d0e0160a?locale=de\n",
    "- Birth statistics (2002-present) https://www.data.gv.at/datasets/f54e6828-3d75-4a82-89cb-23c58057bad4?locale=de\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "import requests\n",
    "import io\n",
    "\n",
    "MONGO_CONFIG = {\n",
    "    'uri': \"mongodb://admin:admin123@localhost:27017/\",\n",
    "    'auth_source': \"admin\",\n",
    "    'database': \"wien_demografie_db\",\n",
    "    'use_docker': True\n",
    "}\n",
    "\n",
    "# Direkte URLs zur Datenquelle\n",
    "URL_BEVOELKERUNG = \"https://www.wien.gv.at/gogv/l9ogdviebezpopsexage5stkcobgeoat102008f\"\n",
    "URL_GEBURTEN = \"https://www.wien.gv.at/gogv/l9ogdviebezpopsexbir2002f\"\n",
    "\n",
    "POPULATION_COLUMNS = {\n",
    "    'REF_YEAR': 'Jahr',\n",
    "    'DISTRICT_CODE': 'Bezirk_Roh',\n",
    "    'SUB_DISTRICT_CODE': 'Sub_Bezirk',\n",
    "    'REF_DATE': 'Datum',\n",
    "    'SEX': 'Geschlecht',\n",
    "    'AGE1': 'Alter',\n",
    "    'UNK': 'Unbekannt',\n",
    "    'BGD': 'Burgenland',\n",
    "    'KTN': 'Kaernten',\n",
    "    'NOE': 'Niederoesterreich',\n",
    "    'OOE': 'Oberoesterreich',\n",
    "    'SBG': 'Salzburg',\n",
    "    'STK': 'Steiermark',\n",
    "    'TIR': 'Tirol',\n",
    "    'VBG': 'Vorarlberg',\n",
    "    'VIE': 'Wien',\n",
    "    'FOR': 'Ausland'\n",
    "}\n",
    "\n",
    "BIRTH_COLUMNS = {\n",
    "    'REF_YEAR': 'Jahr',\n",
    "    'DISTRICT_CODE': 'Bezirk_Roh',\n",
    "    'SUB_DISTRICT_CODE': 'Sub_Bezirk',\n",
    "    'REF_DATE': 'Datum',\n",
    "    'SEX': 'Geschlecht',\n",
    "    'BIR': 'Anzahl_Geburten'\n",
    "}\n",
    "\n",
    "BUNDESLAND_COLUMNS = [\n",
    "    'Unbekannt', 'Burgenland', 'Kaernten', 'Niederoesterreich',\n",
    "    'Oberoesterreich', 'Salzburg', 'Steiermark', 'Tirol',\n",
    "    'Vorarlberg', 'Wien', 'Ausland'\n",
    "]\n",
    "\n",
    "\n",
    "def setup_mongodb():\n",
    "    try:\n",
    "        if MONGO_CONFIG['use_docker']:\n",
    "            client = MongoClient(\n",
    "                MONGO_CONFIG['uri'],\n",
    "                serverSelectionTimeoutMS=5000,\n",
    "                authSource=MONGO_CONFIG['auth_source']\n",
    "            )\n",
    "        else:\n",
    "            client = MongoClient(\n",
    "                MONGO_CONFIG['uri'],\n",
    "                serverSelectionTimeoutMS=5000\n",
    "            )\n",
    "\n",
    "        client.server_info()\n",
    "        db = client[MONGO_CONFIG['database']]\n",
    "        return client, db\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: MongoDB connection failed - {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "def clean_district_code(code):\n",
    "    try:\n",
    "        code_str = str(code).strip()\n",
    "\n",
    "        if code_str.startswith('9') and len(code_str) == 5:\n",
    "            district_num = int(code_str[1:3])\n",
    "            return 1000 + district_num * 10\n",
    "\n",
    "        if code_str.startswith('1') and len(code_str) == 4:\n",
    "            return int(code_str)\n",
    "\n",
    "        return int(code_str)\n",
    "\n",
    "    except (ValueError, TypeError):\n",
    "        return 0\n",
    "\n",
    "def download_csv(url):\n",
    "    \"\"\"Lädt CSV von URL mit Error-Handling und Browser-Header\"\"\"\n",
    "    print(f\"Downloading data from {url}...\")\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        return pd.read_csv(\n",
    "            io.StringIO(response.content.decode('utf-8-sig')),\n",
    "            sep=';',\n",
    "            header=0,\n",
    "            skiprows=1\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL ERROR: Could not download data from {url}. Reason: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def extract_data():\n",
    "    # Daten direkt von den URLs laden\n",
    "    df_pop = download_csv(URL_BEVOELKERUNG)\n",
    "    df_birth = download_csv(URL_GEBURTEN)\n",
    "\n",
    "    print(\"Download successful.\")\n",
    "    return df_pop, df_birth\n",
    "\n",
    "\n",
    "def transform_population_data(df):\n",
    "    rename_map = {k: v for k, v in POPULATION_COLUMNS.items() if k in df.columns}\n",
    "    df = df.rename(columns=rename_map)\n",
    "\n",
    "    if 'Sub_Bezirk' in df.columns:\n",
    "        df['Bezirk'] = df['Sub_Bezirk'].apply(clean_district_code)\n",
    "    elif 'Bezirk_Roh' in df.columns:\n",
    "        df['Bezirk'] = df['Bezirk_Roh'].apply(clean_district_code)\n",
    "    else:\n",
    "        print(\"  WARNING: No district code column found\")\n",
    "        df['Bezirk'] = 0\n",
    "\n",
    "    df = df[df['Bezirk'] > 0]\n",
    "\n",
    "    for col in BUNDESLAND_COLUMNS:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    if 'Jahr' in df.columns:\n",
    "        df['Jahr'] = pd.to_numeric(df['Jahr'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def transform_birth_data(df):\n",
    "    rename_map = {k: v for k, v in BIRTH_COLUMNS.items() if k in df.columns}\n",
    "    df = df.rename(columns=rename_map)\n",
    "\n",
    "    if 'Sub_Bezirk' in df.columns:\n",
    "        df['Bezirk'] = df['Sub_Bezirk'].apply(clean_district_code)\n",
    "    elif 'Bezirk_Roh' in df.columns:\n",
    "        df['Bezirk'] = df['Bezirk_Roh'].apply(clean_district_code)\n",
    "    else:\n",
    "        df['Bezirk'] = 0\n",
    "\n",
    "    df = df[df['Bezirk'] > 0]\n",
    "\n",
    "    if 'Anzahl_Geburten' in df.columns:\n",
    "        df['Anzahl_Geburten'] = pd.to_numeric(\n",
    "            df['Anzahl_Geburten'],\n",
    "            errors='coerce'\n",
    "        ).fillna(0).astype(int)\n",
    "\n",
    "    if 'Jahr' in df.columns:\n",
    "        df['Jahr'] = pd.to_numeric(df['Jahr'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_data_sources(df_pop, df_birth):\n",
    "    # Aggregation vor dem Merge, um Granularitäts-Probleme zu vermeiden\n",
    "    pop_agg = df_pop.groupby(['Jahr', 'Bezirk']).agg({\n",
    "        'Wien': 'sum',\n",
    "        'Ausland': 'sum',\n",
    "        'Geschlecht': 'count' # Platzhalter, Logik ggf. anpassen je nach Analyse-Ziel\n",
    "    }).reset_index()\n",
    "\n",
    "    pop_agg.rename(columns={'Geschlecht': 'Gesamt_Bevoelkerung'}, inplace=True)\n",
    "\n",
    "    birth_agg = df_birth.groupby(['Jahr', 'Bezirk']).agg({\n",
    "        'Anzahl_Geburten': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    merged = pd.merge(pop_agg, birth_agg, on=['Jahr', 'Bezirk'], how='outer')\n",
    "    merged = merged.fillna(0)\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "def transform_data(df_pop, df_birth):\n",
    "    print(\"Transforming data...\")\n",
    "    df_pop_clean = transform_population_data(df_pop)\n",
    "    df_birth_clean = transform_birth_data(df_birth)\n",
    "    df_merged = merge_data_sources(df_pop_clean, df_birth_clean)\n",
    "    return df_pop_clean, df_birth_clean, df_merged\n",
    "\n",
    "\n",
    "def load_data(db, df_pop, df_birth, df_merged):\n",
    "    print(\"Loading data into MongoDB...\")\n",
    "    db.population.delete_many({})\n",
    "    db.births.delete_many({})\n",
    "    db.merged_analysis.delete_many({})\n",
    "\n",
    "    if len(df_pop) > 0:\n",
    "        db.population.insert_many(df_pop.to_dict(\"records\"))\n",
    "\n",
    "    if len(df_birth) > 0:\n",
    "        db.births.insert_many(df_birth.to_dict(\"records\"))\n",
    "\n",
    "    if len(df_merged) > 0:\n",
    "        db.merged_analysis.insert_many(df_merged.to_dict(\"records\"))\n",
    "\n",
    "    print(\"Data load complete.\")\n",
    "\n",
    "\n",
    "def run_pipeline():\n",
    "    client, db = setup_mongodb()\n",
    "    try:\n",
    "        df_pop, df_birth = extract_data()\n",
    "        df_pop_clean, df_birth_clean, df_merged = transform_data(df_pop, df_birth)\n",
    "        load_data(db, df_pop_clean, df_birth_clean, df_merged)\n",
    "        print(\"Pipeline finished successfully.\")\n",
    "    finally:\n",
    "        client.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.wien.gv.at/gogv/l9ogdviebezpopsexage5stkcobgeoat102008f...\n",
      "Downloading data from https://www.wien.gv.at/gogv/l9ogdviebezpopsexbir2002f...\n",
      "Download successful.\n",
      "Transforming data...\n",
      "Loading data into MongoDB...\n"
     ]
    },
    {
     "ename": "OperationFailure",
     "evalue": "Unsupported OP_QUERY command: delete. The client driver may require an upgrade. For more details see https://dochub.mongodb.org/core/legacy-opcode-removal",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOperationFailure\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 240\u001B[0m\n\u001B[1;32m    236\u001B[0m         client\u001B[38;5;241m.\u001B[39mclose()\n\u001B[1;32m    239\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 240\u001B[0m     \u001B[43mrun_pipeline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[10], line 233\u001B[0m, in \u001B[0;36mrun_pipeline\u001B[0;34m()\u001B[0m\n\u001B[1;32m    231\u001B[0m     df_pop, df_birth \u001B[38;5;241m=\u001B[39m extract_data()\n\u001B[1;32m    232\u001B[0m     df_pop_clean, df_birth_clean, df_merged \u001B[38;5;241m=\u001B[39m transform_data(df_pop, df_birth)\n\u001B[0;32m--> 233\u001B[0m     \u001B[43mload_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_pop_clean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_birth_clean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_merged\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeline finished successfully.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "Cell \u001B[0;32mIn[10], line 212\u001B[0m, in \u001B[0;36mload_data\u001B[0;34m(db, df_pop, df_birth, df_merged)\u001B[0m\n\u001B[1;32m    210\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mload_data\u001B[39m(db, df_pop, df_birth, df_merged):\n\u001B[1;32m    211\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoading data into MongoDB...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 212\u001B[0m     \u001B[43mdb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpopulation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdelete_many\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    213\u001B[0m     db\u001B[38;5;241m.\u001B[39mbirths\u001B[38;5;241m.\u001B[39mdelete_many({})\n\u001B[1;32m    214\u001B[0m     db\u001B[38;5;241m.\u001B[39mmerged_analysis\u001B[38;5;241m.\u001B[39mdelete_many({})\n",
      "File \u001B[0;32m~/PycharmProjects/BigDataProject/.venv/lib/python3.9/site-packages/pymongo/collection.py:1190\u001B[0m, in \u001B[0;36mCollection.delete_many\u001B[0;34m(self, filter, collation, session)\u001B[0m\n\u001B[1;32m   1159\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdelete_many\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mfilter\u001B[39m, collation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, session\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1160\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Delete one or more documents matching the filter.\u001B[39;00m\n\u001B[1;32m   1161\u001B[0m \n\u001B[1;32m   1162\u001B[0m \u001B[38;5;124;03m      >>> db.test.count({'x': 1})\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;124;03m    .. versionadded:: 3.0\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   1189\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DeleteResult(\n\u001B[0;32m-> 1190\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_delete_retryable\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mfilter\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msession\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   1192\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrite_concern\u001B[38;5;241m.\u001B[39macknowledged)\n",
      "File \u001B[0;32m~/PycharmProjects/BigDataProject/.venv/lib/python3.9/site-packages/pymongo/collection.py:1120\u001B[0m, in \u001B[0;36mCollection._delete_retryable\u001B[0;34m(self, criteria, multi, write_concern, op_id, ordered, collation, session)\u001B[0m\n\u001B[1;32m   1113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_delete\u001B[39m(session, sock_info, retryable_write):\n\u001B[1;32m   1114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_delete(\n\u001B[1;32m   1115\u001B[0m         sock_info, criteria, multi,\n\u001B[1;32m   1116\u001B[0m         write_concern\u001B[38;5;241m=\u001B[39mwrite_concern, op_id\u001B[38;5;241m=\u001B[39mop_id, ordered\u001B[38;5;241m=\u001B[39mordered,\n\u001B[1;32m   1117\u001B[0m         collation\u001B[38;5;241m=\u001B[39mcollation, session\u001B[38;5;241m=\u001B[39msession,\n\u001B[1;32m   1118\u001B[0m         retryable_write\u001B[38;5;241m=\u001B[39mretryable_write)\n\u001B[0;32m-> 1120\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__database\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retryable_write\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1121\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[43mwrite_concern\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite_concern\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macknowledged\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmulti\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1122\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_delete\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msession\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/BigDataProject/.venv/lib/python3.9/site-packages/pymongo/mongo_client.py:1099\u001B[0m, in \u001B[0;36mMongoClient._retryable_write\u001B[0;34m(self, retryable, func, session)\u001B[0m\n\u001B[1;32m   1097\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Internal retryable write helper.\"\"\"\u001B[39;00m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tmp_session(session) \u001B[38;5;28;01mas\u001B[39;00m s:\n\u001B[0;32m-> 1099\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retry_with_session\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretryable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/BigDataProject/.venv/lib/python3.9/site-packages/pymongo/mongo_client.py:1076\u001B[0m, in \u001B[0;36mMongoClient._retry_with_session\u001B[0;34m(self, retryable, func, session, bulk)\u001B[0m\n\u001B[1;32m   1073\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m is_retrying():\n\u001B[1;32m   1074\u001B[0m             \u001B[38;5;66;03m# Reset the transaction id and retry the operation.\u001B[39;00m\n\u001B[1;32m   1075\u001B[0m             session\u001B[38;5;241m.\u001B[39m_retry_transaction_id()\n\u001B[0;32m-> 1076\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43msession\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msock_info\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretryable\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ServerSelectionTimeoutError:\n\u001B[1;32m   1078\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_retrying():\n\u001B[1;32m   1079\u001B[0m         \u001B[38;5;66;03m# The application may think the write was never attempted\u001B[39;00m\n\u001B[1;32m   1080\u001B[0m         \u001B[38;5;66;03m# if we raise ServerSelectionTimeoutError on the retry\u001B[39;00m\n\u001B[1;32m   1081\u001B[0m         \u001B[38;5;66;03m# attempt. Raise the original exception instead.\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/BigDataProject/.venv/lib/python3.9/site-packages/pymongo/collection.py:1114\u001B[0m, in \u001B[0;36mCollection._delete_retryable.<locals>._delete\u001B[0;34m(session, sock_info, retryable_write)\u001B[0m\n\u001B[1;32m   1113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_delete\u001B[39m(session, sock_info, retryable_write):\n\u001B[0;32m-> 1114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_delete\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1115\u001B[0m \u001B[43m        \u001B[49m\u001B[43msock_info\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriteria\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1116\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwrite_concern\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwrite_concern\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mop_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mordered\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mordered\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1117\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcollation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msession\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1118\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretryable_write\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretryable_write\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/BigDataProject/.venv/lib/python3.9/site-packages/pymongo/collection.py:1091\u001B[0m, in \u001B[0;36mCollection._delete\u001B[0;34m(self, sock_info, criteria, multi, write_concern, op_id, ordered, collation, session, retryable_write)\u001B[0m\n\u001B[1;32m   1087\u001B[0m     command[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwriteConcern\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m concern\n\u001B[1;32m   1089\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m acknowledged:\n\u001B[1;32m   1090\u001B[0m     \u001B[38;5;66;03m# Delete command.\u001B[39;00m\n\u001B[0;32m-> 1091\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43msock_info\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcommand\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1092\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__database\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1093\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1094\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcodec_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__write_response_codec_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1095\u001B[0m \u001B[43m        \u001B[49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msession\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1096\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__database\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1097\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretryable_write\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretryable_write\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1098\u001B[0m     _check_write_command_response(result)\n\u001B[1;32m   1099\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/PycharmProjects/BigDataProject/.venv/lib/python3.9/site-packages/pymongo/pool.py:490\u001B[0m, in \u001B[0;36mSocketInfo.command\u001B[0;34m(self, dbname, spec, slave_ok, read_preference, codec_options, check, allowable_errors, check_keys, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write)\u001B[0m\n\u001B[1;32m    488\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msend_cluster_time(spec, session, client)\n\u001B[1;32m    489\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 490\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcommand\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdbname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mspec\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mslave_ok\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m                   \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_mongos\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mread_preference\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcodec_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m                   \u001B[49m\u001B[43msession\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallowable_errors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m                   \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maddress\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_keys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlisteners\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m                   \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_bson_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mread_concern\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    495\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mparse_write_concern_error\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparse_write_concern_error\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    496\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mcollation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    497\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m OperationFailure:\n\u001B[1;32m    498\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/BigDataProject/.venv/lib/python3.9/site-packages/pymongo/network.py:123\u001B[0m, in \u001B[0;36mcommand\u001B[0;34m(sock, dbname, spec, slave_ok, is_mongos, read_preference, codec_options, session, client, check, allowable_errors, address, check_keys, listeners, max_bson_size, read_concern, parse_write_concern_error, collation)\u001B[0m\n\u001B[1;32m    121\u001B[0m         client\u001B[38;5;241m.\u001B[39m_receive_cluster_time(response_doc, session)\n\u001B[1;32m    122\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m check:\n\u001B[0;32m--> 123\u001B[0m         \u001B[43mhelpers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_command_response\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    124\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresponse_doc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallowable_errors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    125\u001B[0m \u001B[43m            \u001B[49m\u001B[43mparse_write_concern_error\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparse_write_concern_error\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    127\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m publish:\n",
      "File \u001B[0;32m~/PycharmProjects/BigDataProject/.venv/lib/python3.9/site-packages/pymongo/helpers.py:146\u001B[0m, in \u001B[0;36m_check_command_response\u001B[0;34m(response, msg, allowable_errors, parse_write_concern_error)\u001B[0m\n\u001B[1;32m    143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CursorNotFound(errmsg, code, response)\n\u001B[1;32m    145\u001B[0m msg \u001B[38;5;241m=\u001B[39m msg \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 146\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m OperationFailure(msg \u001B[38;5;241m%\u001B[39m errmsg, code, response)\n",
      "\u001B[0;31mOperationFailure\u001B[0m: Unsupported OP_QUERY command: delete. The client driver may require an upgrade. For more details see https://dochub.mongodb.org/core/legacy-opcode-removal"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "bd58c337c5a90c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T13:23:11.643648Z",
     "start_time": "2026-01-09T13:23:09.907589Z"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Wien-Geburten-Zeitverlauf\")\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:10.6.0\")\n",
    "    .config(\n",
    "        \"spark.mongodb.read.connection.uri\",\n",
    "        \"mongodb://admin:admin123@localhost:27017/wien_demografie_db?authSource=admin\"\n",
    "    )\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(spark.version)  # muss 3.5.x sein\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/09 14:23:11 WARN Utils: Your hostname, MacBook-Air-von-Johannes.local resolves to a loopback address: 127.0.0.1; using 10.191.14.22 instead (on interface en0)\n",
      "26/01/09 14:23:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Exception in thread \"main\" java.lang.ExceptionInInitializerError\n",
      "\tat org.apache.spark.unsafe.array.ByteArrayMethods.<clinit>(ByteArrayMethods.java:54)\n",
      "\tat org.apache.spark.internal.config.package$.<init>(package.scala:1006)\n",
      "\tat org.apache.spark.internal.config.package$.<clinit>(package.scala)\n",
      "\tat org.apache.spark.deploy.SparkSubmitArguments.$anonfun$loadEnvironmentArguments$3(SparkSubmitArguments.scala:157)\n",
      "\tat scala.Option.orElse(Option.scala:447)\n",
      "\tat org.apache.spark.deploy.SparkSubmitArguments.loadEnvironmentArguments(SparkSubmitArguments.scala:157)\n",
      "\tat org.apache.spark.deploy.SparkSubmitArguments.<init>(SparkSubmitArguments.scala:115)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$$anon$2$$anon$3.<init>(SparkSubmit.scala:990)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$$anon$2.parseArguments(SparkSubmit.scala:990)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:85)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "Caused by: java.lang.IllegalStateException: java.lang.NoSuchMethodException: java.nio.DirectByteBuffer.<init>(long,int)\n",
      "\tat org.apache.spark.unsafe.Platform.<clinit>(Platform.java:62)\n",
      "\t... 13 more\n",
      "Caused by: java.lang.NoSuchMethodException: java.nio.DirectByteBuffer.<init>(long,int)\n",
      "\tat java.base/java.lang.Class.getConstructor0(Class.java:3833)\n",
      "\tat java.base/java.lang.Class.getDeclaredConstructor(Class.java:3004)\n",
      "\tat org.apache.spark.unsafe.Platform.<clinit>(Platform.java:55)\n",
      "\t... 13 more\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SparkSession\n\u001B[1;32m      3\u001B[0m spark \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m----> 4\u001B[0m     \u001B[43mSparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuilder\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappName\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mWien-Geburten-Zeitverlauf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mspark.jars.packages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43morg.mongodb.spark:mongo-spark-connector_2.12:10.6.0\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mspark.mongodb.read.connection.uri\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmongodb://admin:admin123@localhost:27017/wien_demografie_db?authSource=admin\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetOrCreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m )\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(spark\u001B[38;5;241m.\u001B[39mversion)  \u001B[38;5;66;03m# muss 3.5.x sein\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/BigDataProject/.venv/lib/python3.9/site-packages/pyspark/sql/session.py:186\u001B[0m, in \u001B[0;36mSparkSession.Builder.getOrCreate\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    184\u001B[0m         sparkConf\u001B[38;5;241m.\u001B[39mset(key, value)\n\u001B[1;32m    185\u001B[0m     \u001B[38;5;66;03m# This SparkContext may be an existing one.\u001B[39;00m\n\u001B[0;32m--> 186\u001B[0m     sc \u001B[38;5;241m=\u001B[39m \u001B[43mSparkContext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetOrCreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msparkConf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001B[39;00m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;66;03m# by all sessions.\u001B[39;00m\n\u001B[1;32m    189\u001B[0m session \u001B[38;5;241m=\u001B[39m SparkSession(sc)\n",
      "File \u001B[0;32m~/PycharmProjects/BigDataProject/.venv/lib/python3.9/site-packages/pyspark/context.py:378\u001B[0m, in \u001B[0;36mSparkContext.getOrCreate\u001B[0;34m(cls, conf)\u001B[0m\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    377\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_active_spark_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 378\u001B[0m         \u001B[43mSparkContext\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconf\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mSparkConf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    379\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_active_spark_context\n",
      "File \u001B[0;32m~/PycharmProjects/BigDataProject/.venv/lib/python3.9/site-packages/pyspark/context.py:133\u001B[0m, in \u001B[0;36mSparkContext.__init__\u001B[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m gateway \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m gateway\u001B[38;5;241m.\u001B[39mgateway_parameters\u001B[38;5;241m.\u001B[39mauth_token \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    129\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    130\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    131\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m is not allowed as it is a security risk.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 133\u001B[0m \u001B[43mSparkContext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ensure_initialized\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgateway\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgateway\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    135\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n\u001B[1;32m    136\u001B[0m                   conf, jsc, profiler_cls)\n",
      "File \u001B[0;32m~/PycharmProjects/BigDataProject/.venv/lib/python3.9/site-packages/pyspark/context.py:327\u001B[0m, in \u001B[0;36mSparkContext._ensure_initialized\u001B[0;34m(cls, instance, gateway, conf)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_gateway:\n\u001B[0;32m--> 327\u001B[0m         SparkContext\u001B[38;5;241m.\u001B[39m_gateway \u001B[38;5;241m=\u001B[39m gateway \u001B[38;5;129;01mor\u001B[39;00m \u001B[43mlaunch_gateway\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    328\u001B[0m         SparkContext\u001B[38;5;241m.\u001B[39m_jvm \u001B[38;5;241m=\u001B[39m SparkContext\u001B[38;5;241m.\u001B[39m_gateway\u001B[38;5;241m.\u001B[39mjvm\n\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m instance:\n",
      "File \u001B[0;32m~/PycharmProjects/BigDataProject/.venv/lib/python3.9/site-packages/pyspark/java_gateway.py:105\u001B[0m, in \u001B[0;36mlaunch_gateway\u001B[0;34m(conf, popen_kwargs)\u001B[0m\n\u001B[1;32m    102\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.1\u001B[39m)\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(conn_info_file):\n\u001B[0;32m--> 105\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJava gateway process exited before sending its port number\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    107\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(conn_info_file, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m info:\n\u001B[1;32m    108\u001B[0m     gateway_port \u001B[38;5;241m=\u001B[39m read_int(info)\n",
      "\u001B[0;31mException\u001B[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "258f8772de780236",
   "metadata": {},
   "source": [
    "births_df = (\n",
    "    spark.read.format(\"mongodb\")\n",
    "    .option(\"spark.mongodb.read.collection\", \"births\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "births_df.show(5)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "de09dbae-bdd2-442d-9822-e8dee9a41ff8",
   "metadata": {},
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "population_df = (\n",
    "    spark.read.format(\"mongodb\")\n",
    "    .option(\"spark.mongodb.read.collection\", \"population\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "population_df.printSchema()\n",
    "population_df.show(5)\n",
    "\n",
    "\n",
    "pop_origin_df = (\n",
    "    population_df\n",
    "    .groupBy(\"Jahr\", \"Bezirk\")\n",
    "    .agg(\n",
    "        F.sum(\"Ausland\").alias(\"Bev_Ausland\"),\n",
    "        F.sum(\"Wien\").alias(\"Bev_Wien\")\n",
    "    )\n",
    ")\n",
    "\n",
    "births_agg_df = (\n",
    "    births_df\n",
    "    .groupBy(\"Jahr\", \"Bezirk\")\n",
    "    .agg(F.sum(\"Anzahl_Geburten\").alias(\"Geburten\"))\n",
    ")\n",
    "\n",
    "birth_rate_origin_df = (\n",
    "    births_agg_df\n",
    "    .join(pop_origin_df, [\"Jahr\", \"Bezirk\"])\n",
    "    .withColumn(\n",
    "        \"Geburtenrate_Ausland\",\n",
    "        F.col(\"Geburten\") / F.col(\"Bev_Ausland\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"Geburtenrate_Wien\",\n",
    "        F.col(\"Geburten\") / F.col(\"Bev_Wien\")\n",
    "    )\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f0a0d7f3-22da-4b8c-b9d3-53cfe42ad400",
   "metadata": {},
   "source": [
    "zuwanderung_df = (\n",
    "    population_df\n",
    "    .groupBy(\"Bezirk\")\n",
    "    .agg(\n",
    "        F.sum(\"Ausland\").alias(\"Bev_Ausland\"),\n",
    "        F.sum(\n",
    "            F.col(\"Ausland\") +\n",
    "            F.col(\"Wien\") +\n",
    "            F.col(\"Burgenland\") +\n",
    "            F.col(\"Kaernten\") +\n",
    "            F.col(\"Niederoesterreich\") +\n",
    "            F.col(\"Oberoesterreich\") +\n",
    "            F.col(\"Salzburg\") +\n",
    "            F.col(\"Steiermark\") +\n",
    "            F.col(\"Tirol\") +\n",
    "            F.col(\"Vorarlberg\")\n",
    "        ).alias(\"Bev_Gesamt\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"Auslaenderanteil\",\n",
    "        F.col(\"Bev_Ausland\") / F.col(\"Bev_Gesamt\")\n",
    "    )\n",
    "    .orderBy(F.desc(\"Auslaenderanteil\"))\n",
    ")\n",
    "\n",
    "zuwanderung_df.show(10)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dc81462c-74f9-4088-986e-67a7b6614414",
   "metadata": {},
   "source": [
    "births_agg_df = (\n",
    "    births_df\n",
    "    .groupBy(\"Jahr\", \"Bezirk\")\n",
    "    .agg(F.sum(\"Anzahl_Geburten\").alias(\"Geburten\"))\n",
    ")\n",
    "\n",
    "migration_birth_df = (\n",
    "    births_agg_df\n",
    "    .join(\n",
    "        population_df.groupBy(\"Jahr\", \"Bezirk\")\n",
    "        .agg(F.sum(\"Ausland\").alias(\"Bev_Ausland\")),\n",
    "        [\"Jahr\", \"Bezirk\"]\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"Geburten_pro_1000_Ausland\",\n",
    "        (F.col(\"Geburten\") / F.col(\"Bev_Ausland\")) * 1000\n",
    "    )\n",
    "    .orderBy(F.desc(\"Geburten_pro_1000_Ausland\"))\n",
    ")\n",
    "\n",
    "migration_birth_df.show(10)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "438674a7-d20d-42ee-a257-b749d5849b96",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
